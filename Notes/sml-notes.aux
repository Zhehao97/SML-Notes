\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{nyt/global//global/global}
\HyPL@Entry{0<</S/D>>}
\abx@aux@cite{0}{bach2021learning}
\abx@aux@segm{0}{0}{bach2021learning}
\abx@aux@cite{0}{mohri2018foundations}
\abx@aux@segm{0}{0}{mohri2018foundations}
\abx@aux@cite{0}{shalev2014understanding}
\abx@aux@segm{0}{0}{shalev2014understanding}
\abx@aux@cite{0}{tropp2012user}
\abx@aux@segm{0}{0}{tropp2012user}
\abx@aux@cite{0}{wainwright2019high}
\abx@aux@segm{0}{0}{wainwright2019high}
\abx@aux@page{1}{3}
\abx@aux@page{2}{3}
\abx@aux@page{3}{3}
\abx@aux@page{4}{3}
\abx@aux@page{5}{3}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction to Supervised Learning}{4}{section.1}\protected@file@percent }
\newlabel{sec:introduction_to_supervised_learning}{{1}{4}{Introduction to Supervised Learning}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Decision Theory}{4}{subsection.1.1}\protected@file@percent }
\newlabel{sub:decision_theory}{{1.1}{4}{Decision Theory}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Loss Functions}{4}{subsubsection.1.1.1}\protected@file@percent }
\newlabel{ssub:loss_functions}{{1.1.1}{4}{Loss Functions}{subsubsection.1.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Risks}{4}{subsubsection.1.1.2}\protected@file@percent }
\newlabel{ssub:risks}{{1.1.2}{4}{Risks}{subsubsection.1.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Bayes Risk}{5}{subsubsection.1.1.3}\protected@file@percent }
\newlabel{ssub:bayes_risk}{{1.1.3}{5}{Bayes Risk}{subsubsection.1.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Learning from Data}{8}{subsection.1.2}\protected@file@percent }
\newlabel{sub:learning_from_data}{{1.2}{8}{Learning from Data}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Local Averaging Methods}{9}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{ssub:local_averaging_methods}{{1.2.1}{9}{Local Averaging Methods}{subsubsection.1.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces $k$-nearest-neighbor}}{9}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Empirical Risk Minimiation}{9}{subsubsection.1.2.2}\protected@file@percent }
\newlabel{ssub:empirical_risk_minimiation}{{1.2.2}{9}{Empirical Risk Minimiation}{subsubsection.1.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces empirical risk}}{10}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Statistical Learning Theory}{11}{subsection.1.3}\protected@file@percent }
\newlabel{sub:statistical_learning_theory}{{1.3}{11}{Statistical Learning Theory}{subsection.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Measures of Performance}{11}{subsubsection.1.3.1}\protected@file@percent }
\newlabel{ssub:measures_of_performance}{{1.3.1}{11}{Measures of Performance}{subsubsection.1.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Some Notions in Learning Problems}{12}{subsubsection.1.3.2}\protected@file@percent }
\newlabel{ssub:some_notions_in_learning_problems}{{1.3.2}{12}{Some Notions in Learning Problems}{subsubsection.1.3.2}{}}
\abx@aux@cite{0}{bach2021learning}
\abx@aux@segm{0}{0}{bach2021learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}No Free Lunch Theorems}{13}{subsubsection.1.3.3}\protected@file@percent }
\newlabel{ssub:no_free_lunch_theorems}{{1.3.3}{13}{No Free Lunch Theorems}{subsubsection.1.3.3}{}}
\abx@aux@page{6}{13}
\@writefile{toc}{\contentsline {section}{\numberline {2}Convexification of the Risk}{13}{section.2}\protected@file@percent }
\newlabel{sec:convexification_of_the_risk}{{2}{13}{Convexification of the Risk}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Convex Surrogates}{14}{subsection.2.1}\protected@file@percent }
\newlabel{sub:convex_surrogates}{{2.1}{14}{Convex Surrogates}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Geometric Interpretation of the Support Vector Machine}{15}{subsection.2.2}\protected@file@percent }
\newlabel{sub:geometric_interpretation_of_the_support_vector_machine}{{2.2}{15}{Geometric Interpretation of the Support Vector Machine}{subsection.2.2}{}}
\newlabel{eq:svc-problem}{{2.2}{16}{Geometric Interpretation of the Support Vector Machine}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Conditional Surrogate Risk and Classification Calibration}{17}{subsection.2.3}\protected@file@percent }
\newlabel{sub:conditional_surrogate_risk_and_classification_calibration}{{2.3}{17}{Conditional Surrogate Risk and Classification Calibration}{subsection.2.3}{}}
\abx@aux@cite{0}{bartlett2006convexity}
\abx@aux@segm{0}{0}{bartlett2006convexity}
\newlabel{eq:classification-calibrated}{{2.5}{18}{Conditional Surrogate Risk and Classification Calibration}{equation.2.5}{}}
\abx@aux@page{7}{18}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Classification calibration}}{18}{figure.3}\protected@file@percent }
\newlabel{fig:classfication-calibration}{{3}{18}{Classification calibration}{figure.3}{}}
\newlabel{eq:calibrated-differentiate}{{2.6}{18}{Conditional Surrogate Risk and Classification Calibration}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Relationship between Risk and Surrogate Risk}{19}{subsection.2.4}\protected@file@percent }
\newlabel{sub:relationship_between_risk_and_surrogate_risk}{{2.4}{19}{Relationship between Risk and Surrogate Risk}{subsection.2.4}{}}
\newlabel{lm:excess-risk-bound}{{2.1}{19}{}{theorem.2.1}{}}
\abx@aux@cite{0}{bartlett2006convexity}
\abx@aux@segm{0}{0}{bartlett2006convexity}
\abx@aux@page{8}{20}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The excess risk of hinge loss and $0$-$1$ loss}}{20}{figure.4}\protected@file@percent }
\newlabel{fig:excess-risk-hinge-loss}{{4}{20}{The excess risk of hinge loss and $0$-$1$ loss}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Impact on Approximation Errors}{21}{subsection.2.5}\protected@file@percent }
\newlabel{sub:impact_on_approximation_errors}{{2.5}{21}{Impact on Approximation Errors}{subsection.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Empirical Risk Minimization}{21}{section.3}\protected@file@percent }
\newlabel{sec:empirical_risk_minimization}{{3}{21}{Empirical Risk Minimization}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Risk Minimization Decomposition}{22}{subsection.3.1}\protected@file@percent }
\newlabel{sub:risk_minimization_decomposition}{{3.1}{22}{Risk Minimization Decomposition}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Approximation Error}{22}{subsection.3.2}\protected@file@percent }
\newlabel{sub:approximation_error}{{3.2}{22}{Approximation Error}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The distance between minimizer $\theta _{*}$ and set $\Theta $ on $\mathbb  {R}$}}{23}{figure.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Estimation Error}{23}{subsection.3.3}\protected@file@percent }
\newlabel{sub:estimation_error}{{3.3}{23}{Estimation Error}{subsection.3.3}{}}
\newlabel{eq:estimation-error}{{3.3}{23}{Estimation Error}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Uniform Deviation from Expectation}{23}{subsubsection.3.3.1}\protected@file@percent }
\newlabel{ssub:uniform_deviation_from_expectation}{{3.3.1}{23}{Uniform Deviation from Expectation}{subsubsection.3.3.1}{}}
\newlabel{eq:expected-unifrom-deviation}{{3.4}{24}{Uniform Deviation from Expectation}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Linear Hypothesis Space}{24}{subsubsection.3.3.2}\protected@file@percent }
\newlabel{ssub:linear_hypothesis_space}{{3.3.2}{24}{Linear Hypothesis Space}{subsubsection.3.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Finite Hypothesis Space}{26}{subsubsection.3.3.3}\protected@file@percent }
\newlabel{ssub:finite_hypothesis_space}{{3.3.3}{26}{Finite Hypothesis Space}{subsubsection.3.3.3}{}}
\newlabel{eq:finite-expectation-bounds}{{3.7}{27}{Finite Hypothesis Space}{equation.3.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Beyond the Finite Hypothesis Space}{28}{subsubsection.3.3.4}\protected@file@percent }
\newlabel{ssub:beyond_the_finite_hypothesis_space}{{3.3.4}{28}{Beyond the Finite Hypothesis Space}{subsubsection.3.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The left picture is an example in two dimensions of a covering with Euclidean balls; The right is an example of $l_{\infty }$-balls}}{28}{figure.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}PAC Learning and Uniform Convergence}{29}{section.4}\protected@file@percent }
\newlabel{sec:pac_learn_and_uniform_convergence}{{4}{29}{PAC Learning and Uniform Convergence}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}PAC Learning}{29}{subsection.4.1}\protected@file@percent }
\newlabel{sub:pac_learning}{{4.1}{29}{PAC Learning}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Agnostic PAC Learning}{29}{subsection.4.2}\protected@file@percent }
\newlabel{sub:agnostic_pac_learning}{{4.2}{29}{Agnostic PAC Learning}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Uniform Convergence}{30}{subsection.4.3}\protected@file@percent }
\newlabel{sub:uniform_convergence}{{4.3}{30}{Uniform Convergence}{subsection.4.3}{}}
\newlabel{eq:estimation-error-bound}{{4.1}{30}{Uniform Convergence}{equation.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Rademacher Complexity}{31}{section.5}\protected@file@percent }
\newlabel{sec:rademacher_complexity}{{5}{31}{Rademacher Complexity}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Motivation for Rademacher Complexity}{31}{subsection.5.1}\protected@file@percent }
\newlabel{sub:motivation_for_rademacher_complexity}{{5.1}{31}{Motivation for Rademacher Complexity}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Rademacher Complexity}{32}{subsection.5.2}\protected@file@percent }
\newlabel{sub:rademacher_complexity}{{5.2}{32}{Rademacher Complexity}{subsection.5.2}{}}
\newlabel{eq:empirical-Rademacher-complexity}{{5.4}{32}{Empirical Rademacher Complexity}{equation.5.4}{}}
\newlabel{eq:Rademacher-complexity}{{5.5}{33}{Rademacher Complexity}{equation.5.5}{}}
\newlabel{thm:symmetrization-Rademacher-complexity}{{5.1}{33}{Symmetrization}{equation.5.7}{}}
\newlabel{eq:generalization-bound-Rademacher-complexity}{{5.8}{34}{Generalization bonud via Rademacher Complexity}{equation.5.8}{}}
\newlabel{thm:generalization-bound-Radeamcher-complexity}{{5.2}{34}{Generalization bonud via Rademacher Complexity}{equation.5.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Lipschitz-continuous Losses}{36}{subsection.5.3}\protected@file@percent }
\newlabel{sub:lipschitz_continuous_losses}{{5.3}{36}{Lipschitz-continuous Losses}{subsection.5.3}{}}
\newlabel{eq:Rademacher-complexity-of-hypothesis-class}{{5.11}{37}{Lipschitz-continuous Losses}{equation.5.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Ball-constrained Linear Predictions}{38}{subsection.5.4}\protected@file@percent }
\newlabel{sub:ball_constrained_linear_predictions}{{5.4}{38}{Ball-constrained Linear Predictions}{subsection.5.4}{}}
\newlabel{eq:Rademacher-complexity-of-function-class}{{5.13}{38}{Ball-constrained Linear Predictions}{equation.5.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Putting Things Together (Linear Predictions)}{38}{subsection.5.5}\protected@file@percent }
\newlabel{sub:putting_things_together_}{{5.5}{38}{Putting Things Together (Linear Predictions)}{subsection.5.5}{}}
\abx@aux@cite{0}{sridharan2008fast}
\abx@aux@segm{0}{0}{sridharan2008fast}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}From Constrained to Regularized Estimation}{39}{subsection.5.6}\protected@file@percent }
\newlabel{sub:from_constrained_to_regularized_estimation}{{5.6}{39}{From Constrained to Regularized Estimation}{subsection.5.6}{}}
\newlabel{eq:regularized-empirical-risk}{{5.15}{39}{From Constrained to Regularized Estimation}{equation.5.15}{}}
\abx@aux@page{9}{39}
\@writefile{toc}{\contentsline {section}{\numberline {6}Growth Function and VC-Dimension}{40}{section.6}\protected@file@percent }
\newlabel{sec:growth_function_and_vc_dimension}{{6}{40}{Growth Function and VC-Dimension}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Growth Function}{40}{subsection.6.1}\protected@file@percent }
\newlabel{sub:growth_function}{{6.1}{40}{Growth Function}{subsection.6.1}{}}
\newlabel{eq:growth-function}{{6.1}{40}{Growth Function}{equation.6.1}{}}
\newlabel{thm:Massart-lemma}{{6.1}{40}{Massart's Lemma}{equation.6.2}{}}
\newlabel{eq:generalization-bound-growth-function}{{6.5}{42}{Generalization Bound via Growth Function}{equation.6.5}{}}
\newlabel{thm:generalization-bound-growth-function}{{6.3}{42}{Generalization Bound via Growth Function}{equation.6.5}{}}
\newlabel{eq:direct-generalization-bound-growth-function}{{6.6}{42}{Growth Function}{equation.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}VC-dimension}{42}{subsection.6.2}\protected@file@percent }
\newlabel{sub:vc_dimension}{{6.2}{42}{VC-dimension}{subsection.6.2}{}}
\newlabel{eq:VC-dimension}{{6.7}{42}{VC-dimension}{equation.6.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces An example of a sine function used for classification}}{44}{figure.7}\protected@file@percent }
\newlabel{fig:sine-function}{{7}{44}{An example of a sine function used for classification}{figure.7}{}}
\newlabel{thm:Radon-thm}{{6.4}{44}{Radon's theorem}{theorem.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Link Growth Function and VC-dimension}{45}{subsection.6.3}\protected@file@percent }
\newlabel{sub:link_growth_function_and_vc_dimension}{{6.3}{45}{Link Growth Function and VC-dimension}{subsection.6.3}{}}
\newlabel{eq:generalization-bound-VC-dimension}{{6.11}{45}{Generalization Bounds via VC-dimension}{equation.6.11}{}}
\abx@aux@cite{0}{mohri2018foundations}
\abx@aux@segm{0}{0}{mohri2018foundations}
\newlabel{thm:generalization-bound-VC-dimension}{{6.7}{46}{Generalization Bounds via VC-dimension}{equation.6.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Lower Bounds}{46}{subsection.6.4}\protected@file@percent }
\newlabel{sub:lower_bounds}{{6.4}{46}{Lower Bounds}{subsection.6.4}{}}
\abx@aux@page{10}{46}
\@writefile{toc}{\contentsline {section}{\numberline {7}Covering Number and Chaining}{46}{section.7}\protected@file@percent }
\newlabel{sec:covering_number_and_chaining}{{7}{46}{Covering Number and Chaining}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Covering and Packing}{46}{subsection.7.1}\protected@file@percent }
\newlabel{sub:covering_and_packing}{{7.1}{46}{Covering and Packing}{subsection.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Covering and packing sets}}{48}{figure.8}\protected@file@percent }
\newlabel{fig:covering-packing}{{8}{48}{Covering and packing sets}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Bound Rademacher Complexity via Covering Number}{49}{subsection.7.2}\protected@file@percent }
\newlabel{sub:bound_rademacher_complexity_via_covering_number}{{7.2}{49}{Bound Rademacher Complexity via Covering Number}{subsection.7.2}{}}
\newlabel{thm:covering-bound-Rademacher-complexity}{{7.3}{50}{Bounding Rademacher Complexity via Covering Number}{equation.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Chaining}{50}{subsection.7.3}\protected@file@percent }
\newlabel{sub:chaining}{{7.3}{50}{Chaining}{subsection.7.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Optimization Algorithm}{52}{section.8}\protected@file@percent }
\newlabel{sec:optimization_algorithm}{{8}{52}{Optimization Algorithm}{section.8}{}}
\newlabel{tab:optimization-algo-rate}{{8}{52}{Optimization Algorithm}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Optimization in Machine Learning}{52}{subsection.8.1}\protected@file@percent }
\newlabel{sub:optimization_in_machine_learning}{{8.1}{52}{Optimization in Machine Learning}{subsection.8.1}{}}
\abx@aux@cite{0}{bach2021learning}
\abx@aux@segm{0}{0}{bach2021learning}
\@writefile{toc}{\contentsline {section}{\numberline {9}Kernel Methods}{53}{section.9}\protected@file@percent }
\newlabel{sec:kernel_methods}{{9}{53}{Kernel Methods}{section.9}{}}
\abx@aux@page{11}{53}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Motivating Example to Kernel Function}{53}{subsection.9.1}\protected@file@percent }
\newlabel{sub:motivating_example_to_kernel_function}{{9.1}{53}{Motivating Example to Kernel Function}{subsection.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces XOR classification problem}}{53}{figure.9}\protected@file@percent }
\newlabel{fig:XOR}{{9}{53}{XOR classification problem}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Separating hyperplane}}{54}{figure.10}\protected@file@percent }
\newlabel{fig:SVM}{{10}{54}{Separating hyperplane}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Inner product in feature space}}{55}{figure.11}\protected@file@percent }
\newlabel{fig:SVM-feature-space}{{11}{55}{Inner product in feature space}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Reproducing Kernel Hilbert Space}{56}{subsection.9.2}\protected@file@percent }
\newlabel{sub:reproducing_kernel_hilbert_space}{{9.2}{56}{Reproducing Kernel Hilbert Space}{subsection.9.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1}Hilbert Space}{56}{subsubsection.9.2.1}\protected@file@percent }
\newlabel{ssub:hilbert_space}{{9.2.1}{56}{Hilbert Space}{subsubsection.9.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2}Positive Semidefinite Kernel Functions}{57}{subsubsection.9.2.2}\protected@file@percent }
\newlabel{ssub:positive_semidefinite_kernel_functions}{{9.2.2}{57}{Positive Semidefinite Kernel Functions}{subsubsection.9.2.2}{}}
\newlabel{eq:feature-map}{{9.3}{58}{Polynomial Kernels}{equation.9.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.3}Constructing an RKHS from a Kernel}{58}{subsubsection.9.2.3}\protected@file@percent }
\newlabel{ssub:constructing_an_rkhs_from_a_kernel}{{9.2.3}{58}{Constructing an RKHS from a Kernel}{subsubsection.9.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.4}Alternative Way to Construct RKHS}{58}{subsubsection.9.2.4}\protected@file@percent }
\newlabel{ssub:alternative_way_to_construct_rkhs}{{9.2.4}{58}{Alternative Way to Construct RKHS}{subsubsection.9.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Algorithms}{58}{subsection.9.3}\protected@file@percent }
\newlabel{sub:algorithms}{{9.3}{58}{Algorithms}{subsection.9.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Local Averaging Methods}{58}{section.10}\protected@file@percent }
\newlabel{sec:local_averaging_methods}{{10}{58}{Local Averaging Methods}{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Quick Review}{58}{subsection.10.1}\protected@file@percent }
\newlabel{sub:quick_review}{{10.1}{58}{Quick Review}{subsection.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Local Averaging Methods}{60}{subsection.10.2}\protected@file@percent }
\newlabel{sub:local_averaging_methods}{{10.2}{60}{Local Averaging Methods}{subsection.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Linear Estimator}{61}{subsection.10.3}\protected@file@percent }
\newlabel{sub:linear_estimator}{{10.3}{61}{Linear Estimator}{subsection.10.3}{}}
\newlabel{eq:local-avg-linear-estimator}{{10.5}{61}{Linear Estimator}{equation.10.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.1}Partition Estimators}{61}{subsubsection.10.3.1}\protected@file@percent }
\newlabel{ssub:partition_estimators}{{10.3.1}{61}{Partition Estimators}{subsubsection.10.3.1}{}}
\newlabel{eq:partition-weight}{{10.7}{61}{Partition Estimators}{equation.10.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Regressograms in $d=1$ dimension, with three different values of $|J|$. We can see both underfitting, or overfitting in this example. Note that the target function $f^*$ is piecewise affine, and that on the affine parts, the estimator is far from linear, namely, the estimator cannot take advantage of extra-regularity.}}{62}{figure.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.2}Nearest-Neighbors}{63}{subsubsection.10.3.2}\protected@file@percent }
\newlabel{ssub:nearest_neighbors}{{10.3.2}{63}{Nearest-Neighbors}{subsubsection.10.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces $k$-nearest neighbor regression in $d = 1$ dimension, with three values of $k$ (the number of neighbors). We can see both underfitting ($k$ too large), and overfitting ($k$ too small).}}{63}{figure.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.3}Nadaraya-Watson Estimator (Kernel Regression)}{63}{subsubsection.10.3.3}\protected@file@percent }
\newlabel{ssub:nadaraya_watson_estimator_kernel_regression_}{{10.3.3}{63}{Nadaraya-Watson Estimator (Kernel Regression)}{subsubsection.10.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Nadaraya-Watson regression in $d=1$ dimension, with three values of bandwidth $h$ for the Gaussian kernel.}}{64}{figure.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Generic Simplest Consistency Analysis}{64}{subsection.10.4}\protected@file@percent }
\newlabel{sub:generic_simplest_consistency_analysis}{{10.4}{64}{Generic Simplest Consistency Analysis}{subsection.10.4}{}}
\abx@aux@page{12}{67}
\abx@aux@page{13}{67}
\abx@aux@page{14}{67}
\abx@aux@page{15}{67}
\abx@aux@page{16}{67}
\abx@aux@page{17}{67}
\abx@aux@page{18}{67}
\@writefile{toc}{\contentsline {section}{\numberline {A}Norms}{68}{appendix.1.A}\protected@file@percent }
\newlabel{sec:norms}{{A}{68}{Norms}{appendix.1.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Norms}{68}{subsection.1.A.1}\protected@file@percent }
\newlabel{sub:norms}{{A.1}{68}{Norms}{subsection.1.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Examples of Norm}{68}{subsection.1.A.2}\protected@file@percent }
\newlabel{sub:examples_of_norm}{{A.2}{68}{Examples of Norm}{subsection.1.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Equivalence of Norms}{69}{subsection.1.A.3}\protected@file@percent }
\newlabel{sub:equivalence_of_norms}{{A.3}{69}{Equivalence of Norms}{subsection.1.A.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Operator Norms}{69}{subsection.1.A.4}\protected@file@percent }
\newlabel{sub:operator_norms}{{A.4}{69}{Operator Norms}{subsection.1.A.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Probability Theory}{70}{appendix.1.B}\protected@file@percent }
\newlabel{sec:probability_theory}{{B}{70}{Probability Theory}{appendix.1.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Independence}{70}{subsection.1.B.1}\protected@file@percent }
\newlabel{sub:independence}{{B.1}{70}{Independence}{subsection.1.B.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Expectations}{72}{subsection.1.B.2}\protected@file@percent }
\newlabel{sub:expectations}{{B.2}{72}{Expectations}{subsection.1.B.2}{}}
\newlabel{def:cond-expectation}{{B.4}{72}{}{definition.1.B.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Convergences}{75}{subsection.1.B.3}\protected@file@percent }
\newlabel{sub:convergences}{{B.3}{75}{Convergences}{subsection.1.B.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Concentration of Measure}{80}{appendix.1.C}\protected@file@percent }
\newlabel{sec:concentration_of_measure}{{C}{80}{Concentration of Measure}{appendix.1.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Markov Inequality}{80}{subsection.1.C.1}\protected@file@percent }
\newlabel{sub:markov_inequality}{{C.1}{80}{Markov Inequality}{subsection.1.C.1}{}}
\newlabel{eq:Markov}{{C.1}{80}{Markov Inequality}{equation.1.C.1}{}}
\newlabel{eq:Markov-higher-moment}{{C.2}{80}{Markov Inequality}{equation.1.C.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Chebyshev Inequality}{80}{subsection.1.C.2}\protected@file@percent }
\newlabel{sub:chebyshev_inequality}{{C.2}{80}{Chebyshev Inequality}{subsection.1.C.2}{}}
\newlabel{eq:Chebyshev}{{C.3}{80}{Chebyshev Inequality}{equation.1.C.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Chernoff's Methods}{81}{subsection.1.C.3}\protected@file@percent }
\newlabel{sub:chernoff_s_methods}{{C.3}{81}{Chernoff's Methods}{subsection.1.C.3}{}}
\newlabel{eq:Chernoff}{{C.4}{81}{Chernoff Bound}{equation.1.C.4}{}}
\newlabel{eq:Rademacher-tail}{{C.5}{81}{MGF of Rademacher Variables}{equation.1.C.5}{}}
\newlabel{eq:Bounded-tail}{{C.6}{82}{MGF of Bounded Variables}{equation.1.C.6}{}}
\newlabel{eq:Gaussian-tail-bound}{{C.7}{82}{Gaussian Tail Bound}{equation.1.C.7}{}}
\newlabel{eq:Gaussian-tail}{{C.8}{83}{Chernoff's Methods}{equation.1.C.8}{}}
\newlabel{eq:sub-Gaussian-tail}{{C.9}{83}{Sub-Gaussian Tail Bound}{equation.1.C.9}{}}
\newlabel{eq:Sub-Gaussian-tail-bound}{{C.10}{84}{Sub-Gaussian Tail Bound}{equation.1.C.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Hoeffding's Inequality}{84}{subsection.1.C.4}\protected@file@percent }
\newlabel{sub:hoeffding_s_inequality}{{C.4}{84}{Hoeffding's Inequality}{subsection.1.C.4}{}}
\newlabel{eq:Hoeffding}{{C.12}{84}{Hoeffding's Inequality}{equation.1.C.12}{}}
\newlabel{eq:Hoeffding-lemma}{{C.14}{85}{Hoeffding's Inequality}{equation.1.C.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.5}Bernstein's Inequality}{86}{subsection.1.C.5}\protected@file@percent }
\newlabel{sub:bernstein_s_inequality}{{C.5}{86}{Bernstein's Inequality}{subsection.1.C.5}{}}
\newlabel{eq:Bernstein}{{C.15}{86}{Berstein's Inequality}{equation.1.C.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.6}McDiarmid's Inequality}{87}{subsection.1.C.6}\protected@file@percent }
\newlabel{sub:mcdiarmid_s_inequality}{{C.6}{87}{McDiarmid's Inequality}{subsection.1.C.6}{}}
\newlabel{eq:McDiarmid}{{C.16}{87}{McDiarmid's Inequality}{equation.1.C.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.7}Expectation of the Maximum}{88}{subsection.1.C.7}\protected@file@percent }
\newlabel{sub:expectation_of_the_maximum}{{C.7}{88}{Expectation of the Maximum}{subsection.1.C.7}{}}
\newlabel{thm:expectation-of-maximum}{{C.13}{88}{Expectation of the Maximum}{theorem.1.C.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Concentration for Matrices}{89}{appendix.1.D}\protected@file@percent }
\newlabel{sec:concentration_for_matrices}{{D}{89}{Concentration for Matrices}{appendix.1.D}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Matrix Analysis}{89}{subsection.1.D.1}\protected@file@percent }
\newlabel{sub:matrix_analysis}{{D.1}{89}{Matrix Analysis}{subsection.1.D.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1.1}Matrix Functions}{89}{subsubsection.1.D.1.1}\protected@file@percent }
\newlabel{ssub:matrix_functions}{{D.1.1}{89}{Matrix Functions}{subsubsection.1.D.1.1}{}}
\newlabel{eq:matrix-function}{{D.1}{89}{Matrix Functions}{equation.1.D.1}{}}
\newlabel{eq:transfer-rule}{{D.2}{89}{Matrix Functions}{equation.1.D.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1.2}Matrix Exponential}{89}{subsubsection.1.D.1.2}\protected@file@percent }
\newlabel{ssub:matrix_exponential}{{D.1.2}{89}{Matrix Exponential}{subsubsection.1.D.1.2}{}}
\newlabel{eq:matrix-exponential}{{D.4}{89}{Matrix Exponential}{equation.1.D.4}{}}
\newlabel{eq:monotone-trace-exponential}{{D.5}{89}{Matrix Exponential}{equation.1.D.5}{}}
\newlabel{eq:Golden-Thompson}{{D.6}{89}{Matrix Exponential}{equation.1.D.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1.3}Matrix Logarithm}{90}{subsubsection.1.D.1.3}\protected@file@percent }
\newlabel{ssub:matrix_logarithm}{{D.1.3}{90}{Matrix Logarithm}{subsubsection.1.D.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1.4}Expectation and the Semidefinite Order}{90}{subsubsection.1.D.1.4}\protected@file@percent }
\newlabel{ssub:expectation_and_the_semidefinite_order}{{D.1.4}{90}{Expectation and the Semidefinite Order}{subsubsection.1.D.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1.5}Matrix Martingales}{90}{subsubsection.1.D.1.5}\protected@file@percent }
\newlabel{ssub:matrix_martingales}{{D.1.5}{90}{Matrix Martingales}{subsubsection.1.D.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Tail Bounds via the Matrix Laplace Transform Method}{91}{subsection.1.D.2}\protected@file@percent }
\newlabel{sub:tail_bounds_via_the_matrix_laplace_transform_method}{{D.2}{91}{Tail Bounds via the Matrix Laplace Transform Method}{subsection.1.D.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2.1}Matrix Moments and Cumulants}{91}{subsubsection.1.D.2.1}\protected@file@percent }
\newlabel{ssub:matrix_moments_and_cumulants}{{D.2.1}{91}{Matrix Moments and Cumulants}{subsubsection.1.D.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2.2}Laplace Transform Method}{91}{subsubsection.1.D.2.2}\protected@file@percent }
\newlabel{ssub:laplace_transform_method}{{D.2.2}{91}{Laplace Transform Method}{subsubsection.1.D.2.2}{}}
\newlabel{prop:Laplace-transform}{{D.1}{91}{The Laplace Transform Method}{equation.1.D.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2.3}Failure of the Matrix MGF}{92}{subsubsection.1.D.2.3}\protected@file@percent }
\newlabel{ssub:failure_of_the_matrix_mgf}{{D.2.3}{92}{Failure of the Matrix MGF}{subsubsection.1.D.2.3}{}}
\newlabel{eq:scalar-mgf-multiplication}{{D.13}{92}{Failure of the Matrix MGF}{equation.1.D.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2.4}A Concave Trace Function}{92}{subsubsection.1.D.2.4}\protected@file@percent }
\newlabel{ssub:a_concave_trace_function}{{D.2.4}{92}{A Concave Trace Function}{subsubsection.1.D.2.4}{}}
\newlabel{col:concave-trace-exponential}{{D.2}{92}{}{theorem.1.D.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2.5}Subadditivity of the Matrix CGF}{92}{subsubsection.1.D.2.5}\protected@file@percent }
\newlabel{ssub:subadditivity_of_the_matrix_cgf}{{D.2.5}{92}{Subadditivity of the Matrix CGF}{subsubsection.1.D.2.5}{}}
\newlabel{eq:scalar-cgf-multiplication}{{D.14}{92}{Subadditivity of the Matrix CGF}{equation.1.D.14}{}}
\newlabel{lm:subadditivity-matrix-cgf}{{D.3}{93}{Subadditiveity of Matrix CGF's}{equation.1.D.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2.6}Tail Bounds of Independent Sums}{93}{subsubsection.1.D.2.6}\protected@file@percent }
\newlabel{ssub:tail_bounds_of_independent_sums}{{D.2.6}{93}{Tail Bounds of Independent Sums}{subsubsection.1.D.2.6}{}}
\newlabel{eq:master-tail-bound-independent-sum}{{D.17}{93}{Master Tail Bound for Independence Sums}{equation.1.D.17}{}}
\newlabel{col:tail-bound-independent-sum}{{D.5}{94}{}{equation.1.D.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.3}Matrix Gaussian and Rademacher}{95}{subsection.1.D.3}\protected@file@percent }
\newlabel{sub:matrix_gaussian_and_rademacher}{{D.3}{95}{Matrix Gaussian and Rademacher}{subsection.1.D.3}{}}
\newlabel{lm:Rademacher-Gaussian-MGF}{{D.6}{95}{Rademacher and Gaussian MGF's}{equation.1.D.21}{}}
\newlabel{eq:matrix-Gaussian-Rademacher-bound}{{D.22}{96}{Matrix Gaussian and Rademacher Series}{equation.1.D.22}{}}
\newlabel{eq:matrix-Gaussian-Rademacher-norm-bound}{{D.23}{96}{Matrix Gaussian and Rademacher Series}{equation.1.D.23}{}}
\newlabel{thm:matrix-Gaussian-Rademacher-tail}{{D.7}{96}{Matrix Gaussian and Rademacher Series}{equation.1.D.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.4}Matrix Bennett and Bernstein Bounds}{97}{subsection.1.D.4}\protected@file@percent }
\newlabel{sub:matrix_bennett_and_bernstein_bounds}{{D.4}{97}{Matrix Bennett and Bernstein Bounds}{subsection.1.D.4}{}}
\newlabel{lm:bounded-Bernstein-MGF}{{D.8}{97}{Bounded Bernstein MGF}{theorem.1.D.8}{}}
\newlabel{thm:matrix-Bernstein-bounded}{{D.9}{98}{Matrix Bernstein - Bounded Case}{equation.1.D.25}{}}
\newlabel{thm:matrix-Bernstein-subexponential}{{D.10}{99}{Matrix Bernstein - Subexponential Case}{equation.1.D.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.5}Matrix Hoeffding and Azuma and McDiarmid}{99}{subsection.1.D.5}\protected@file@percent }
\newlabel{sub:matrix_hoeffding_and_azuma_and_mcdiarmid}{{D.5}{99}{Matrix Hoeffding and Azuma and McDiarmid}{subsection.1.D.5}{}}
\newlabel{lm:symmetrization}{{D.11}{99}{Symmetrization}{equation.1.D.27}{}}
\newlabel{lm:Azuma-CGF}{{D.12}{100}{Azuma CGF}{theorem.1.D.12}{}}
\newlabel{thm:matrix-Azuma}{{D.13}{100}{Matrix Azuma}{equation.1.D.28}{}}
\abx@aux@read@bbl@mdfivesum{B7CF336F1A4ADAC986C2D3C21393DB68}
\abx@aux@defaultrefcontext{0}{bach2021learning}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{bartlett2006convexity}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{mohri2018foundations}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{shalev2014understanding}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{sridharan2008fast}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{tropp2012user}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wainwright2019high}{nyt/global//global/global}
\gdef \@abspage@last{101}
